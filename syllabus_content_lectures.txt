SECTION
<a name = "timedomain">Unit 1: Time Domain Audio Processing</a>
We will begin our foray into digital audio processing by thinking of audio as a big, long 1D array.  Under typical conditions, we have 44100 elements for every second of audio.  This means we have nearly a million elements in our arrays for only 20 seconds of audio!  We'll also see that the elements of this array, known as "audio samples," are a bit of a mess, but we'll be able to do a surprising amount by manipulating the samples, and we'll be able to create some cool sounds by synthesizing samples from equations.  Students will also get more comfortable with python and numpy in the stage of the course.

LECTURE
Course Overview, Sneak Preview, Digital Audio Representations

<ul><li><a href = "https://docs.google.com/presentation/d/1ZCVGhQweUCB8a_h9R-X4ZE5U4cVLXLcl1bUhcM91woY/edit?usp=sharing">Slides from today</a></li><li><a href = "ClassExercises/Week1/Week1_AudioReverseGame">Audio Reverse Game</a></li></ul>
LECTURE
Python/Numpy Basics, Slicing/Reversing Audio, Sinusoids/Pitch, Sample Rate/Dimensional Analysis

<ul><a href = "https://donsheehy.github.io/datastructures/fullbook.pdf">Sheehy</a> Ch. 2 for python intro</li></ul>
LECTURE
Square Waves, Triangle Waves, Sawtooth Waves, Noise, Beat Frequencies


LECTURE
Octaves, Harmonicity, Circle of Fifths / Pythagorean Tuning

<ul><li><a href = "ClassExercises/Week2/Week2_Harmonicity">Harmonicity Notes</a></li><li><a href = "https://en.wikipedia.org/wiki/Pythagorean_comma">Wikipedia Notes on The Pythagorean Comma</a></li></ul>
LECTURE
Finish Pythagorean Tuning, Chirps, Vibrato, Frequency Sonification


LECTURE
Square Wave Tunes, Risset Beats with Phase Aggregation

<ul><li><a href = "Assignments/HW1_RissetBeats/HappyBirthdaySquareWaves.html">Happy Birthday Square Waves</a></li><li><a href = "Assignments/HW1_RissetBeats/PhaseAggregation.html">Phase Aggregation (Part 2) Notes</a></li> </ul>
LECTURE
Zero Crossings, Consonant/Vowel Filtering, Dynamics, Intensity, Loudness


LECTURE
Timbre, FM Synthesis, ADSR

<ul><li><a href = "https://web.eecs.umich.edu/~fessler/course/100/misc/chowning-73-tso.pdf">John Chowning's 1973 paper on FM synthesis</a></li><li><a href = "https://en.wikipedia.org/wiki/Yamaha_DX7">Yamaha DX7</a></li><li><a href = "https://ccrma.stanford.edu/">Stanford CCRMA</a></li></ul>
LECTURE
Echoes / Impulse Responses / Convolution

<ul><li><a href = "http://www.echothief.com/">Echo Thief</a><li><a href = "https://www.youtube.com/watch?v=aT2YGXxYx-w">Impluse response of a nuclear power plant</a></li></ul>
LECTURE
Comb Filters


LECTURE
Shepard Tones


SECTION
<a name = "freqdomain">Unit 2: Frequency Domain Audio Processing</a>
We are now ready to introduce one of the most important tools in this class: the Discrete Fourier Transform (DFT).  As it turns out, every possible sound can be represented as a sum of sines and cosines at different frequencies!  If we examine the amplitudes of these sines/cosines instead of the audio samples directly, this can give us a lot more insight into what's actually going on.  This is because, as we observed last semester, we perceive anything "periodic" (that repeats itself in time) as a pitch, and sines/cosines are the fudamental building blocks of any periodic signal.  Hence, the DFT describes audio with numbers that are much closer to what we perceive about the audio than the raw audio samples.

LECTURE
Discovering The Discrete Fourier Transform (DFT), Real-Valued DFT Definition


LECTURE
Amplitude/Phase Shifts, Exploring The DFT on Audio Data: Pitch And Timbre, Fast(er) Risset Beats


LECTURE
Converting Frequency Units on Real Audio, Begin The Short-Time Fourier Transform (STFT)


LECTURE
The Short-Time Fourier Transform (STFT), Spectrograms

<ul><li><a href = "https://musiclab.chromeexperiments.com/spectrogram">Live spectrogram demo in the browser</a></li></ul>
LECTURE
Complex Numbers Review, Euler's Formula, Complex Definition of DFT And Phase

<ul><li><a href = "https://www.youtube.com/watch?v=Ffka-hPzug0">The Other Square Wave</a> (i.e. how we don't pereceive constant phase offsets)</li></ul>
LECTURE
Phasor Mirroring, Aliasing


LECTURE
Inverse Complex DFT/STFT, Vocoder Concept, Phase Retrieval


LECTURE
Convolution/multiplication duality, FFTConvolve


LECTURE
The Z-Transform, Lowpass Filters / Highpass Filters, frequency analysis of comb filters

<ul><li><a href = "https://learningsynths.ableton.com/filters/filters-in-the-real-world">Ableton: Filters in The Real World</a></li></ul>
LECTURE
DFT-Based Filter Design, Infinite Impulse Response (IIR) Filters</p>

<ul><li><a href = "https://demonstrations.wolfram.com/DigitalIIRFilterDesignShowingPolesAndZeros">Wolfram Demo on IIR Filter Design with Poles/Zeroes</a></li></ul>
SECTION
<a name = "classical">Unit 3: Classical Algorithms For Digital Music Processing</a>
Now that we have frequency domain tools down, we're going to build things on top of it to address a wide variety of higher level problems, including: <ul><li>Tempo estimation and beat tracking</li><li>Fundamental frequency tracking</li><li>The "Shazam algorithm" for audio fingerprinting</li><li>Segment boundary detection in music</li><li>Cross-version comparison and time warping</li><li>"Un-mixing" audio, or separating audio into its tracks</li></ul>All of these problems can be accomplished with straightforward mathematical algorithms built on top of the Short-Time Fourier Transform (STFT).

LECTURE
Rhythm, Beats, And Audio novelty functions


LECTURE
Matrix Multiplication And Mel Spectrograms, Autocorrelation for Tempo Estimation


LECTURE
Linear Predictive Coding (LPC)

<ul><li><a href = "https://ccrma.stanford.edu/~hskim08/lpc/">Hyunk-Suk Kim's Notes on Linear Predictive Coding</a></li></ul>
LECTURE
Chroma Features, Shepard Tones

<ul><li><a href = "https://www.youtube.com/watch?v=YUOR7_40-dQ">Shepard Tone Visualization</a></li><li><a href = "https://www.youtube.com/watch?v=6niz-JVb_6Q">Dorian Concept - 'Toothbrush'</a></li></ul>
LECTURE
Self-Similarity in Audio, Segment Boundary Detection

<ul><li><a href = "https://dl.acm.org/doi/pdf/10.1145/319463.319472">Foote 1999 Paper: Visualizing music and audio using self-similarity</a></a></li><li><a href = "https://en.wikipedia.org/wiki/Arthur_Lintgen">Arthur Lintgen bio</a></li><li><a href = "https://arxiv.org/pdf/1902.01023.pdf">Tralie 2019 Paper</a></li><li><a href = "http://www.covers1000.net/GraphDitty/">Graph Ditty</a></li></ul>
LECTURE
Cross-Similarity Matrices, Dynamic Time Warping

<ul><li><a href = "https://ursinus-cs472a-s2021.github.io/Modules/Module17/Video0">CS 472 Module on Dynamic Time Warping</a></li><li><a href = "https://ursinus-cs371-s2022.github.io/CoursePage/ClassExercises/DTWNotes/">CS 371 Notes on Dynamic Time Warping</a></li><li><a href = "http://www.ctralie.com/Research/linmdtw/">Linear memory dynamic time warping</a></li></ul>
LECTURE
Dynamic Programming Beat Tracking

<ul><li><a href = "ClassExercises/BeattrackNotes">Notes on dynamic programming beat tracking</a></li></ul>
LECTURE
Harmonic-Percussive Source Separation, Matrix Multiplication for Audio Activations

<ul><li><a href = "../Modules/Module18/Video0">Class notes on HPSS</a></li><li><a href = "https://www.researchgate.net/profile/Derry-Fitzgerald/publication/254583990_HarmonicPercussive_Separation_using_Median_Filtering/links/00b495396ef03235af000000/Harmonic-Percussive-Separation-using-Median-Filtering.pdf">FitzGerald 2010 Paper</a></li></ul>
LECTURE
Source Separation via Nonnegative matrix factorization (NMF)

<ul><li><a href = "ClassExercises/Week10/Week10_NMF">Class Notes on NMF</a></li><li><a href = "https://papers.nips.cc/paper/2000/file/f9d1152547c0bde01830b7e8bd60024c-Paper.pdf">Original Lee/Seung Paper on NMF</a></li></ul>
LECTURE
Audio Fingerprints / The Shazam Algorithm

<ul><li><a href = "https://www.princeton.edu/~cuff/ele201/files/Wang03-shazam.pdf">The original Shazam Paper</a></li><li><a href = "https://github.com/ursinus-cs372-s2023/pyshazam">Our Python Implementation of Shazam</a></li><li><a href = "https://slideslive.com/38917442/characterizing-musical-correlates-of-largescale-discovery-behavior?ref=speaker-19235">Blair Kaneshiro Talk</a></li><li><a href = "https://www.youtube.com/watch?v=puVYtkh-LO4">Cinco Midi Organiser</a></li>
LECTURE
Fundamental Frequency Estimation (Module), Autotuners (Class)

<ul><li><a href = "https://www.justinsalamon.com/news/replace-your-favourite-singer-with-a-robot">Justin Salamon: Replace Your Favorite Singer With a Robot</a></li></ul>
SECTION
<a name = "neuralnets">Unit 4: Data Driven Digital Music Processing</a>
<p>In the prior unit, we built on spectrograms to do a variety of tasks using <b>hand-crafted models</b> to pick up on different audio attributes.  In this unit, we will talk about modern methods for <b>data-driven</b> audio analysis.  Rather than going in with too many preconceived notions about what we need to do to pick up on particular audio attributes, we will work to collect labeled data that captures what we want the computer to be able to do, and then we will let the computer tell us what patterns exist in the data that allow us to do certain tasks.  For instance, we will gather a large collection of notes being played on a violin, and we will learn how to synthesize violin notes from this data.  We will also discuss how to do pitch estimation by learning from a large collection of audio clips where the pitches are annotated.  By the end of the unit, we will look at</p><p>In general, the approach of learning to generalize from labeled data examples is known as <a href = "https://www.ibm.com/topics/supervised-learning">supervised learning</a>.  Though there are a <a href = "https://scikit-learn.org/stable/supervised_learning.html#supervised-learning">variety of techniques</a> to do this, we will focus primarily on <b>deep neural networks</b>, as they have shown the most promise for audio analysis and synthesis over the past few years.  As such, this is the most "cutting edge" unit in the course.  We will take advantage of the <a href = "https://pytorch.org/">pytorch</a> library to help us do this effectively.</p><p>During the last 4 classes, we will dive into some very recent papers using deep neural networks applied to pitch tracking, demixing, instrument style transfer, and track synthesis based on a large language model.  Because these models are computationally expensive to train, we will focus on a <b>"user's guide"</b> to running pretrained networks for each of them.</p>

LECTURE
Logistic Regression, Introduction To pytorch and data loaders

<ul><li><a href = "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">PyTorch Datasets & DataLoaders Documentation</a></li></ul>
LECTURE
Logistic Regression: Separating Square Waves from Sawtooth Waves


LECTURE
Neural Networks And Deep Learning

<ul><li><a href = "https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">3Blue1Brown Intro To Neural Nets</a></li></ul>
LECTURE
SIRENs: Implicit Neural Representations with Periodic Activation Functions

<ul><li><a href = "https://www.vincentsitzmann.com/siren/">Original 2020 NeurIPS paper on SIRENs</a></li></ul>
LECTURE
Differentiable Digital Signal Processing

<ul><li><a href = "https://magenta.tensorflow.org/ddsp">Google Magenta DDSP Blog Post</a></li></ul>
LECTURE
Convolutional Neural Networks, Data Augmentation


LECTURE
<u>A User's Guide:</u> CREPE for fundamental frequency estimation

<ul><li><a href = "https://www.justinsalamon.com/uploads/4/3/9/4/4394963/kim_crepe_icassp_2018.pdf">Jong Wook Kimg 2018: CREPE: A Convolutional Representation for Pitch Estimation</li></ul>
LECTURE
<u>A User's Guide:</u> Demucs for track demixing

<ul><li><a href = "https://github.com/facebookresearch/demucs/tree/v2">Facebook research demucs link</a></li></ul>
LECTURE
<u>A User's Guide:</u> Rave for audio to audio style transfer

<ul><li><a href = "https://github.com/acids-ircam/RAVE">IRCAM Rave Page</a></li></ul>
LECTURE
<u>A User's Guide:</u> Stable Audio for track synthesis with a large language model

<ul><li><a href = "https://arxiv.org/pdf/2407.14358">2024 Paper on stable audio</a></li></ul>
